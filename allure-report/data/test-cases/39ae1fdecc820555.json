{"uid":"39ae1fdecc820555","name":"testcase description","fullName":"testcases.test1.TestCaseDemo2#test_start","historyId":"94719bd2e0989e9e0aa14632c096a2a8","time":{"start":1661139088295,"stop":1661139088499,"duration":204},"description":"TestCase ID: 4519284d-2781-4183-8592-313f5fc49579","descriptionHtml":"<p>TestCase ID: 4519284d-2781-4183-8592-313f5fc49579</p>\n","status":"broken","statusMessage":"httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 404(int)\nassert_method: equal\nexpect_value: 200(int)\nassert headers.\"Content-Type\" equal application/json; charset=utf-8(str)\t==> fail\ncheck_item: headers.\"Content-Type\"\ncheck_value: text/plain(str)\nassert_method: equal\nexpect_value: application/json; charset=utf-8(str)\nassert body.msg equal ok(str)\t==> fail\ncheck_item: body.msg\ncheck_value: None(NoneType)\nassert_method: equal\nexpect_value: ok(str)\nassert body.status equal 1(int)\t==> fail\ncheck_item: body.status\ncheck_value: None(NoneType)\nassert_method: equal\nexpect_value: 1(int)","statusTrace":"self = <test1.TestCaseDemo2 object at 0x00000286FF278D90>, param = None\n\n    def test_start(self, param: Dict = None) -> \"SessionRunner\":\n        \"\"\"main entrance, discovered by pytest\"\"\"\n        print(\"\\n\")\n        self.__init()\n        self.__parse_config(param)\n    \n        if ALLURE is not None and not self.__is_referenced:\n            # update allure report meta\n            ALLURE.dynamic.title(self.__config.name)\n            ALLURE.dynamic.description(f\"TestCase ID: {self.case_id}\")\n    \n        logger.info(\n            f\"Start to run testcase: {self.__config.name}, TestCase ID: {self.case_id}\"\n        )\n    \n        logger.add(self.__log_path, format=LOGGER_FORMAT, level=\"DEBUG\")\n        self.__start_at = time.time()\n        try:\n            # run step in sequential order\n            for step in self.teststeps:\n>               self.__run_step(step)\n\nvenv_test\\lib\\site-packages\\httprunner\\runner.py:231: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nvenv_test\\lib\\site-packages\\httprunner\\runner.py:188: in __run_step\n    step_result: StepResult = step.run(self)\nvenv_test\\lib\\site-packages\\httprunner\\step.py:67: in run\n    return self.__step.run(runner)\nvenv_test\\lib\\site-packages\\httprunner\\step_request.py:348: in run\n    return run_step_request(runner, self.__step)\nvenv_test\\lib\\site-packages\\httprunner\\step_request.py:176: in run_step_request\n    resp_obj.validate(validators, variables_mapping)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <httprunner.response.ResponseObject object at 0x00000286FF618790>\nvalidators = [{'equal': ['status_code', 200, '']}, {'equal': ['headers.\"Content-Type\"', 'application/json; charset=utf-8', '']}, {'equal': ['body.msg', 'ok', '']}, {'equal': ['body.status', 1, '']}]\nvariables_mapping = {'request': {'allow_redirects': True, 'cookies': {}, 'data': None, 'headers': {'Authorization': 'Bearer eyJhbGciOiJIUz...GE3OTcxOCIsInV1aWQiOiJiNWRhOTI2YS1hOGY5LTQwYmYtYmIwZi0xYTM5NTVjNTBmOGYifQ.mXyZG_19qVPhKv8PKxEC9KXi2_51TCtmKGdGkMlpmOY'}\n\n    def validate(\n        self,\n        validators: Validators,\n        variables_mapping: VariablesMapping = None,\n    ):\n    \n        variables_mapping = variables_mapping or {}\n    \n        self.validation_results = {}\n        if not validators:\n            return\n    \n        validate_pass = True\n        failures = []\n    \n        for v in validators:\n    \n            if \"validate_extractor\" not in self.validation_results:\n                self.validation_results[\"validate_extractor\"] = []\n    \n            u_validator = uniform_validator(v)\n    \n            # check item\n            check_item = u_validator[\"check\"]\n            if \"$\" in check_item:\n                # check_item is variable or function\n                check_item = self.parser.parse_data(check_item, variables_mapping)\n                check_item = parse_string_value(check_item)\n    \n            if check_item and isinstance(check_item, Text):\n                check_value = self._search_jmespath(check_item)\n            else:\n                # variable or function evaluation result is \"\" or not text\n                check_value = check_item\n    \n            # comparator\n            assert_method = u_validator[\"assert\"]\n            assert_func = self.parser.get_mapping_function(assert_method)\n    \n            # expect item\n            expect_item = u_validator[\"expect\"]\n            # parse expected value with config/teststep/extracted variables\n            expect_value = self.parser.parse_data(expect_item, variables_mapping)\n    \n            # message\n            message = u_validator[\"message\"]\n            # parse message with config/teststep/extracted variables\n            message = self.parser.parse_data(message, variables_mapping)\n    \n            validate_msg = f\"assert {check_item} {assert_method} {expect_value}({type(expect_value).__name__})\"\n    \n            validator_dict = {\n                \"comparator\": assert_method,\n                \"check\": check_item,\n                \"check_value\": check_value,\n                \"expect\": expect_item,\n                \"expect_value\": expect_value,\n                \"message\": message,\n            }\n    \n            try:\n                assert_func(check_value, expect_value, message)\n                validate_msg += \"\\t==> pass\"\n                logger.info(validate_msg)\n                validator_dict[\"check_result\"] = \"pass\"\n            except AssertionError as ex:\n                validate_pass = False\n                validator_dict[\"check_result\"] = \"fail\"\n                validate_msg += \"\\t==> fail\"\n                validate_msg += (\n                    f\"\\n\"\n                    f\"check_item: {check_item}\\n\"\n                    f\"check_value: {check_value}({type(check_value).__name__})\\n\"\n                    f\"assert_method: {assert_method}\\n\"\n                    f\"expect_value: {expect_value}({type(expect_value).__name__})\"\n                )\n                message = str(ex)\n                if message:\n                    validate_msg += f\"\\nmessage: {message}\"\n    \n                logger.error(validate_msg)\n                failures.append(validate_msg)\n    \n            self.validation_results[\"validate_extractor\"].append(validator_dict)\n    \n        if not validate_pass:\n            failures_string = \"\\n\".join([failure for failure in failures])\n>           raise ValidationFailure(failures_string)\nE           httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\nE           check_item: status_code\nE           check_value: 404(int)\nE           assert_method: equal\nE           expect_value: 200(int)\nE           assert headers.\"Content-Type\" equal application/json; charset=utf-8(str)\t==> fail\nE           check_item: headers.\"Content-Type\"\nE           check_value: text/plain(str)\nE           assert_method: equal\nE           expect_value: application/json; charset=utf-8(str)\nE           assert body.msg equal ok(str)\t==> fail\nE           check_item: body.msg\nE           check_value: None(NoneType)\nE           assert_method: equal\nE           expect_value: ok(str)\nE           assert body.status equal 1(int)\t==> fail\nE           check_item: body.status\nE           check_value: None(NoneType)\nE           assert_method: equal\nE           expect_value: 1(int)\n\nvenv_test\\lib\\site-packages\\httprunner\\response.py:254: ValidationFailure","flaky":false,"newFailed":false,"newBroken":false,"newPassed":false,"retriesCount":0,"retriesStatusChange":false,"beforeStages":[],"testStage":{"description":"TestCase ID: 4519284d-2781-4183-8592-313f5fc49579","status":"broken","statusMessage":"httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 404(int)\nassert_method: equal\nexpect_value: 200(int)\nassert headers.\"Content-Type\" equal application/json; charset=utf-8(str)\t==> fail\ncheck_item: headers.\"Content-Type\"\ncheck_value: text/plain(str)\nassert_method: equal\nexpect_value: application/json; charset=utf-8(str)\nassert body.msg equal ok(str)\t==> fail\ncheck_item: body.msg\ncheck_value: None(NoneType)\nassert_method: equal\nexpect_value: ok(str)\nassert body.status equal 1(int)\t==> fail\ncheck_item: body.status\ncheck_value: None(NoneType)\nassert_method: equal\nexpect_value: 1(int)","statusTrace":"self = <test1.TestCaseDemo2 object at 0x00000286FF278D90>, param = None\n\n    def test_start(self, param: Dict = None) -> \"SessionRunner\":\n        \"\"\"main entrance, discovered by pytest\"\"\"\n        print(\"\\n\")\n        self.__init()\n        self.__parse_config(param)\n    \n        if ALLURE is not None and not self.__is_referenced:\n            # update allure report meta\n            ALLURE.dynamic.title(self.__config.name)\n            ALLURE.dynamic.description(f\"TestCase ID: {self.case_id}\")\n    \n        logger.info(\n            f\"Start to run testcase: {self.__config.name}, TestCase ID: {self.case_id}\"\n        )\n    \n        logger.add(self.__log_path, format=LOGGER_FORMAT, level=\"DEBUG\")\n        self.__start_at = time.time()\n        try:\n            # run step in sequential order\n            for step in self.teststeps:\n>               self.__run_step(step)\n\nvenv_test\\lib\\site-packages\\httprunner\\runner.py:231: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nvenv_test\\lib\\site-packages\\httprunner\\runner.py:188: in __run_step\n    step_result: StepResult = step.run(self)\nvenv_test\\lib\\site-packages\\httprunner\\step.py:67: in run\n    return self.__step.run(runner)\nvenv_test\\lib\\site-packages\\httprunner\\step_request.py:348: in run\n    return run_step_request(runner, self.__step)\nvenv_test\\lib\\site-packages\\httprunner\\step_request.py:176: in run_step_request\n    resp_obj.validate(validators, variables_mapping)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <httprunner.response.ResponseObject object at 0x00000286FF618790>\nvalidators = [{'equal': ['status_code', 200, '']}, {'equal': ['headers.\"Content-Type\"', 'application/json; charset=utf-8', '']}, {'equal': ['body.msg', 'ok', '']}, {'equal': ['body.status', 1, '']}]\nvariables_mapping = {'request': {'allow_redirects': True, 'cookies': {}, 'data': None, 'headers': {'Authorization': 'Bearer eyJhbGciOiJIUz...GE3OTcxOCIsInV1aWQiOiJiNWRhOTI2YS1hOGY5LTQwYmYtYmIwZi0xYTM5NTVjNTBmOGYifQ.mXyZG_19qVPhKv8PKxEC9KXi2_51TCtmKGdGkMlpmOY'}\n\n    def validate(\n        self,\n        validators: Validators,\n        variables_mapping: VariablesMapping = None,\n    ):\n    \n        variables_mapping = variables_mapping or {}\n    \n        self.validation_results = {}\n        if not validators:\n            return\n    \n        validate_pass = True\n        failures = []\n    \n        for v in validators:\n    \n            if \"validate_extractor\" not in self.validation_results:\n                self.validation_results[\"validate_extractor\"] = []\n    \n            u_validator = uniform_validator(v)\n    \n            # check item\n            check_item = u_validator[\"check\"]\n            if \"$\" in check_item:\n                # check_item is variable or function\n                check_item = self.parser.parse_data(check_item, variables_mapping)\n                check_item = parse_string_value(check_item)\n    \n            if check_item and isinstance(check_item, Text):\n                check_value = self._search_jmespath(check_item)\n            else:\n                # variable or function evaluation result is \"\" or not text\n                check_value = check_item\n    \n            # comparator\n            assert_method = u_validator[\"assert\"]\n            assert_func = self.parser.get_mapping_function(assert_method)\n    \n            # expect item\n            expect_item = u_validator[\"expect\"]\n            # parse expected value with config/teststep/extracted variables\n            expect_value = self.parser.parse_data(expect_item, variables_mapping)\n    \n            # message\n            message = u_validator[\"message\"]\n            # parse message with config/teststep/extracted variables\n            message = self.parser.parse_data(message, variables_mapping)\n    \n            validate_msg = f\"assert {check_item} {assert_method} {expect_value}({type(expect_value).__name__})\"\n    \n            validator_dict = {\n                \"comparator\": assert_method,\n                \"check\": check_item,\n                \"check_value\": check_value,\n                \"expect\": expect_item,\n                \"expect_value\": expect_value,\n                \"message\": message,\n            }\n    \n            try:\n                assert_func(check_value, expect_value, message)\n                validate_msg += \"\\t==> pass\"\n                logger.info(validate_msg)\n                validator_dict[\"check_result\"] = \"pass\"\n            except AssertionError as ex:\n                validate_pass = False\n                validator_dict[\"check_result\"] = \"fail\"\n                validate_msg += \"\\t==> fail\"\n                validate_msg += (\n                    f\"\\n\"\n                    f\"check_item: {check_item}\\n\"\n                    f\"check_value: {check_value}({type(check_value).__name__})\\n\"\n                    f\"assert_method: {assert_method}\\n\"\n                    f\"expect_value: {expect_value}({type(expect_value).__name__})\"\n                )\n                message = str(ex)\n                if message:\n                    validate_msg += f\"\\nmessage: {message}\"\n    \n                logger.error(validate_msg)\n                failures.append(validate_msg)\n    \n            self.validation_results[\"validate_extractor\"].append(validator_dict)\n    \n        if not validate_pass:\n            failures_string = \"\\n\".join([failure for failure in failures])\n>           raise ValidationFailure(failures_string)\nE           httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\nE           check_item: status_code\nE           check_value: 404(int)\nE           assert_method: equal\nE           expect_value: 200(int)\nE           assert headers.\"Content-Type\" equal application/json; charset=utf-8(str)\t==> fail\nE           check_item: headers.\"Content-Type\"\nE           check_value: text/plain(str)\nE           assert_method: equal\nE           expect_value: application/json; charset=utf-8(str)\nE           assert body.msg equal ok(str)\t==> fail\nE           check_item: body.msg\nE           check_value: None(NoneType)\nE           assert_method: equal\nE           expect_value: ok(str)\nE           assert body.status equal 1(int)\t==> fail\nE           check_item: body.status\nE           check_value: None(NoneType)\nE           assert_method: equal\nE           expect_value: 1(int)\n\nvenv_test\\lib\\site-packages\\httprunner\\response.py:254: ValidationFailure","steps":[{"name":"step: 刷新token","time":{"start":1661139088299,"stop":1661139088460,"duration":161},"status":"passed","steps":[],"attachments":[{"uid":"7aed068009c5be91","name":"request details","source":"7aed068009c5be91.txt","type":"text/plain","size":921},{"uid":"133293c571bf339e","name":"response details","source":"133293c571bf339e.txt","type":"text/plain","size":747}],"parameters":[],"attachmentsCount":2,"shouldDisplayMessage":false,"stepsCount":0,"hasContent":true},{"name":"step: my接口","time":{"start":1661139088460,"stop":1661139088497,"duration":37},"status":"broken","statusMessage":"httprunner.exceptions.ValidationFailure: assert status_code equal 200(int)\t==> fail\ncheck_item: status_code\ncheck_value: 404(int)\nassert_method: equal\nexpect_value: 200(int)\nassert headers.\"Content-Type\" equal application/json; charset=utf-8(str)\t==> fail\ncheck_item: headers.\"Content-Type\"\ncheck_value: text/plain(str)\nassert_method: equal\nexpect_value: application/json; charset=utf-8(str)\nassert body.msg equal ok(str)\t==> fail\ncheck_item: body.msg\ncheck_value: None(NoneType)\nassert_method: equal\nexpect_value: ok(str)\nassert body.status equal 1(int)\t==> fail\ncheck_item: body.status\ncheck_value: None(NoneType)\nassert_method: equal\nexpect_value: 1(int)\n","statusTrace":"  File \"D:\\py\\apitest\\venv_test\\lib\\site-packages\\httprunner\\runner.py\", line 188, in __run_step\n    step_result: StepResult = step.run(self)\n  File \"D:\\py\\apitest\\venv_test\\lib\\site-packages\\httprunner\\step.py\", line 67, in run\n    return self.__step.run(runner)\n  File \"D:\\py\\apitest\\venv_test\\lib\\site-packages\\httprunner\\step_request.py\", line 348, in run\n    return run_step_request(runner, self.__step)\n  File \"D:\\py\\apitest\\venv_test\\lib\\site-packages\\httprunner\\step_request.py\", line 176, in run_step_request\n    resp_obj.validate(validators, variables_mapping)\n  File \"D:\\py\\apitest\\venv_test\\lib\\site-packages\\httprunner\\response.py\", line 254, in validate\n    raise ValidationFailure(failures_string)\n","steps":[],"attachments":[{"uid":"18800da86dabf471","name":"request details","source":"18800da86dabf471.txt","type":"text/plain","size":914},{"uid":"a4c1edab1833405e","name":"response details","source":"a4c1edab1833405e.txt","type":"text/plain","size":299}],"parameters":[],"attachmentsCount":2,"shouldDisplayMessage":true,"stepsCount":0,"hasContent":true}],"attachments":[{"uid":"fe357e0da3dbf593","name":"all log","source":"fe357e0da3dbf593.txt","type":"text/plain","size":8843},{"uid":"d632e534921b66da","name":"stdout","source":"d632e534921b66da.txt","type":"text/plain","size":2},{"uid":"6f3d19e459c4b39b","name":"stderr","source":"6f3d19e459c4b39b.txt","type":"text/plain","size":10014}],"parameters":[],"attachmentsCount":7,"shouldDisplayMessage":true,"stepsCount":2,"hasContent":true},"afterStages":[],"labels":[{"name":"parentSuite","value":"testcases"},{"name":"suite","value":"test1"},{"name":"subSuite","value":"TestCaseDemo2"},{"name":"host","value":"win11x"},{"name":"thread","value":"13144-MainThread"},{"name":"framework","value":"pytest"},{"name":"language","value":"cpython3"},{"name":"package","value":"testcases.test1"},{"name":"resultFormat","value":"allure2"}],"parameters":[],"links":[],"hidden":false,"retry":false,"extra":{"severity":"normal","retries":[],"categories":[{"name":"Test defects","matchedStatuses":[],"flaky":false}],"tags":[]},"source":"39ae1fdecc820555.json","parameterValues":[]}